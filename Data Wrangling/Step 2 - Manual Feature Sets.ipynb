{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dabb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc,os,random\n",
    "import time,datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051fec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a11721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,cols,is_drop=True):\n",
    "    for col in cols:\n",
    "        print('one hot encoding:',col)\n",
    "        dummies = pd.get_dummies(pd.Series(df[col]),prefix='oneHot_%s'%col)\n",
    "        df = pd.concat([df,dummies],axis=1)\n",
    "    if is_drop:\n",
    "        df.drop(cols,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def cat_feature(df):\n",
    "    print(\"Categorical Function Called\")\n",
    "    one_hot_features = [col for col in df.columns if 'oneHot' in col]\n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum', 'last'])\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[one_hot_features].agg(['mean', 'std', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "\n",
    "    if lastk is None:\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['last', 'nunique'])\n",
    "    else:\n",
    "        cat_agg_df = df.groupby(\"customer_ID\",sort=False)[cat_features].agg(['nunique'])\n",
    "    cat_agg_df.columns = ['_'.join(x) for x in cat_agg_df.columns]\n",
    "\n",
    "    count_agg_df = df.groupby(\"customer_ID\",sort=False)[['S_2']].agg(['count'])\n",
    "    count_agg_df.columns = ['_'.join(x) for x in count_agg_df.columns]\n",
    "    df = pd.concat([num_agg_df, cat_agg_df,count_agg_df], axis=1).reset_index()\n",
    "    print('cat feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def num_feature(df):\n",
    "    print(\"Numerical Function Called\")\n",
    "    if num_features[0][:5] == 'rank_':\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['last'])\n",
    "    else:\n",
    "        if lastk is None:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "        else:\n",
    "            num_agg_df = df.groupby(\"customer_ID\",sort=False)[num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "    if num_features[0][:5] != 'rank_':\n",
    "        for col in num_agg_df.columns:\n",
    "            num_agg_df[col] = num_agg_df[col] // 0.01\n",
    "    df = num_agg_df.reset_index()\n",
    "    print('num feature shape after engineering', df.shape )\n",
    "\n",
    "    return df\n",
    "\n",
    "def diff_feature(df):\n",
    "    print(\"Lag Function Called\")\n",
    "    diff_num_features = [f'diff_{col}' for col in num_features]\n",
    "    cids = df['customer_ID'].values\n",
    "    df = df.groupby('customer_ID')[num_features].diff().add_prefix('diff_')\n",
    "    df.insert(0,'customer_ID',cids)\n",
    "    if lastk is None:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum', 'last'])\n",
    "    else:\n",
    "        num_agg_df = df.groupby(\"customer_ID\",sort=False)[diff_num_features].agg(['mean', 'std', 'min', 'max', 'sum'])\n",
    "    num_agg_df.columns = ['_'.join(x) for x in num_agg_df.columns]\n",
    "    for col in num_agg_df.columns:\n",
    "        num_agg_df[col] = num_agg_df[col] // 0.01\n",
    "\n",
    "    df = num_agg_df.reset_index()\n",
    "    print('diff feature shape after engineering', df.shape )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e197b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cpu = os.cpu_count()\n",
    "transform = [['','rank_','ym_rank_'],[''],['']]\n",
    "parquet_list = [os.path.join(config[\"WRANGLED_DATA\"], \"denoised_train\", path)\n",
    "                for path in os.listdir(os.path.join(config[\"WRANGLED_DATA\"], \n",
    "                                                    \"denoised_train\"))] + \\\n",
    "               [os.path.join(config[\"WRANGLED_DATA\"], \"denoised_test\", path)\n",
    "                for path in os.listdir(os.path.join(config[\"WRANGLED_DATA\"], \n",
    "                                                    \"denoised_test\"))]\n",
    "n_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " None\n",
      "Load Parquet Files\n",
      "Process Parquet Files\n",
      "one hot encoding: B_30\n",
      "one hot encoding: B_38\n",
      "one hot encoding: D_114\n",
      "one hot encoding: D_116\n",
      "one hot encoding: D_117\n",
      "one hot encoding: D_120\n",
      "one hot encoding: D_126\n",
      "one hot encoding: D_63\n",
      "one hot encoding: D_64\n",
      "one hot encoding: D_66\n",
      "one hot encoding: D_68\n"
     ]
    }
   ],
   "source": [
    "for li, lastk in enumerate([None,3,6]):\n",
    "    for prefix in transform[li]:\n",
    "        print(prefix, lastk)\n",
    "        print(\"Load Parquet Files\")\n",
    "        ddf = dd.read_parquet(parquet_list)\n",
    "        df = ddf.compute()\n",
    "        \n",
    "        print(\"Process Parquet Files\")\n",
    "        all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "        cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "        num_features = [col for col in all_cols if col not in cat_features]\n",
    "        for col in [col for col in df.columns if 'S_' in col or 'P_' in col]:\n",
    "            if col != 'S_2':\n",
    "                df[col] = df[col].fillna(0)\n",
    "\n",
    "        if lastk is not None:\n",
    "            prefix = f'last{lastk}_' + prefix\n",
    "            print('all df shape',df.shape)\n",
    "            df['rank'] = df.groupby('customer_ID')['S_2'].rank(ascending=False)\n",
    "            df = df.loc[df['rank']<=lastk].reset_index(drop=True)\n",
    "            df = df.drop(['rank'],axis=1)\n",
    "            print(f'last {lastk} shape',df.shape)\n",
    "\n",
    "        if prefix == 'rank_':\n",
    "            cids = df['customer_ID'].values\n",
    "            df = df.groupby('customer_ID')[num_features].rank(pct=True).add_prefix('rank_')\n",
    "            df.insert(0,'customer_ID',cids)\n",
    "            num_features = [f'rank_{col}' for col in num_features]\n",
    "\n",
    "        if prefix == 'ym_rank_':\n",
    "            cids = df['customer_ID'].values\n",
    "            df['ym'] = df['S_2'].apply(lambda x:x[:7])\n",
    "            df = df.groupby('ym')[num_features].rank(pct=True).add_prefix('ym_rank_')\n",
    "            num_features = [f'ym_rank_{col}' for col in num_features]\n",
    "            df.insert(0,'customer_ID',cids)\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "            df = one_hot_encoding(df,cat_features,False)\n",
    "\n",
    "        vc = df['customer_ID'].value_counts(sort=False).cumsum()\n",
    "        batch_size = int(np.ceil(len(vc) / n_cpu))\n",
    "        dfs = []\n",
    "        start = 0\n",
    "        for i in range(min(n_cpu,int(np.ceil(len(vc) / batch_size)))):\n",
    "            vc_ = vc[i*batch_size:(i+1)*batch_size]\n",
    "            dfs.append(df[start:vc_[-1]])\n",
    "            start = vc_[-1]\n",
    "\n",
    "        pool = ThreadPool(n_cpu)\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "            cat_feature_df = pd.concat(pool.map(cat_feature,dfs)).reset_index(drop=True)\n",
    "            cat_feature_df.to_parquet(config[\"WRANGLED_DATA\"] + f'/{prefix}cat_feature.parquet')\n",
    "\n",
    "        if prefix in ['','last3_','last6_','rank_','ym_rank_']:\n",
    "            num_feature_df = pd.concat(pool.map(num_feature,dfs)).reset_index(drop=True)\n",
    "            num_feature_df.to_parquet(config[\"WRANGLED_DATA\"] + f'/{prefix}num_feature.parquet')\n",
    "\n",
    "        if prefix in ['','last3_']:\n",
    "            diff_feature_df = pd.concat(pool.map(diff_feature,dfs)).reset_index(drop=True)\n",
    "            diff_feature_df.to_parquet(config[\"WRANGLED_DATA\"] + f'/{prefix}diff_feature.parquet')\n",
    "\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d34fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
