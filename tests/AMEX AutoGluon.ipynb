{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1bb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49601d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>...</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>6.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>3.017046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  \\\n",
       "0  0.933824  0.024194  0.868580  0.960384  0.934745   0.230769  0.832050   \n",
       "1  0.899820  0.022119  0.861109  0.929122  0.880519   7.153846  6.743468   \n",
       "2  0.878454  0.028911  0.797670  0.904482  0.880875   0.000000  0.000000   \n",
       "3  0.598969  0.020107  0.567442  0.623392  0.621776   1.538462  3.017046   \n",
       "4  0.891679  0.042325  0.805045  0.940382  0.871900   0.000000  0.000000   \n",
       "\n",
       "   D_39_min  D_39_max  D_39_last  ...  D_64_count  D_64_last  D_64_nunique  \\\n",
       "0         0         3          0  ...          13          0             1   \n",
       "1         0        19          6  ...          13          0             1   \n",
       "2         0         0          0  ...          13          2             1   \n",
       "3         0         9          0  ...          13          0             1   \n",
       "4         0         0          0  ...          13          0             1   \n",
       "\n",
       "   D_66_count  D_66_last  D_66_nunique  D_68_count  D_68_last  D_68_nunique  \\\n",
       "0          13         -1             1          13          6             1   \n",
       "1          13         -1             1          13          6             1   \n",
       "2          13         -1             1          13          6             1   \n",
       "3          13         -1             1          13          3             3   \n",
       "4          13          1             1          13          6             1   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 919 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dotenv_values('../.env')\n",
    "train = pd.read_parquet(config[\"ENGINEERED_DATA\"] + \"train_fe.parquet\")\n",
    "train.drop('customer_ID', axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb97d6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictClass\"\n",
      "Presets specified: ['optimize_for_deployment']\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"agModels-predictClass\\\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    458913\n",
      "Train Data Columns: 918\n",
      "Label Column: target\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4095.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1854.93 MB (45.3% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 45.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 67 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['R_23_min']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 633 | ['P_2_mean', 'P_2_std', 'P_2_min', 'P_2_max', 'P_2_last', ...]\n",
      "\t\t('int', [])   : 284 | ['D_39_min', 'D_39_max', 'D_39_last', 'D_44_min', 'D_44_max', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 633 | ['P_2_mean', 'P_2_std', 'P_2_min', 'P_2_max', 'P_2_last', ...]\n",
      "\t\t('int', [])       : 217 | ['D_39_min', 'D_39_max', 'D_39_last', 'D_44_min', 'D_44_max', ...]\n",
      "\t\t('int', ['bool']) :  67 | ['R_2_min', 'R_2_max', 'R_2_last', 'S_6_min', 'S_6_max', ...]\n",
      "\t32.3s = Fit runtime\n",
      "\t917 features in original data used to generate 917 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1854.47 MB (15.7% of available memory)\n",
      "\tWarning: Data size post feature transformation consumes 15.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "Data preprocessing and feature engineering runtime = 34.67s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.5, Train Rows: 229456, Val Rows: 229457\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 3565.33s of the 3565.32s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 6.736 GB, but only 8.103 GB is available...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.265076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.265\t = Validation score   (-root_mean_squared_error)\n",
      "\t194.29s\t = Training   runtime\n",
      "\t4.68s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3366.26s of the 3366.25s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model, roughly requires: 6.736 GB, but only 7.204 GB is available...\n",
      "\tNot enough memory to train LightGBM... Skipping this model.\n",
      "Fitting model: CatBoost ... Training model for up to 3362.96s of the 3362.95s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train CatBoost model, roughly requires: 6.736 GB, but only 7.203 GB is available...\n",
      "C:\\Users\\Kaleb\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "\t-0.2645\t = Validation score   (-root_mean_squared_error)\n",
      "\t708.47s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 2653.95s of the 2653.94s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model, roughly requires: 9.291 GB, but only 8.308 GB is available...\n",
      "\tNot enough memory to train NeuralNetFastAI... Skipping this model.\n",
      "Fitting model: XGBoost ... Training model for up to 2650.69s of the 2650.69s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train XGBoost model, roughly requires: 6.736 GB, but only 8.307 GB is available...\n",
      "\t-0.2668\t = Validation score   (-root_mean_squared_error)\n",
      "\t167.73s\t = Training   runtime\n",
      "\t7.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 2475.48s of the 2475.47s of remaining time.\n",
      "\t-0.316\t = Validation score   (-root_mean_squared_error)\n",
      "\t379.72s\t = Training   runtime\n",
      "\t24.97s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2070.76s of the 2070.75s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model, roughly requires: 6.736 GB, but only 9.866 GB is available...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.265228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2652\t = Validation score   (-root_mean_squared_error)\n",
      "\t220.73s\t = Training   runtime\n",
      "\t3.96s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1845.17s of remaining time.\n",
      "\t-0.2633\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1760.77s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Deleting model XGBoost. All files under agModels-predictClass\\models\\XGBoost\\ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass\\\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label='target', \n",
    "                             problem_type='regression',\n",
    "                             path=save_path).fit(train, \n",
    "                                                 presets='optimize_for_deployment',\n",
    "                                                 hyperparameters= {'NN_TORCH':{}, 'FASTAI':{},\n",
    "                                                                   'GBM': [{'extra_trees': True,\n",
    "                                                                            'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge',], \n",
    "                                                                   'CAT': {}, \n",
    "                                                                   'XGB': {},\n",
    "                                                                  },\n",
    "                                                 holdout_frac=0.5, \n",
    "                                                 time_limit=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2719032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0985bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(\"agModels-predictClass/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f88397",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(train[train.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "046421e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8468989226094761\n"
     ]
    }
   ],
   "source": [
    "print(amex_metric_mod(train[\"target\"].values, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df8a5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facc041e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>...</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.601387</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>0.631315</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>3.527668</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862166</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.794469</td>\n",
       "      <td>0.913501</td>\n",
       "      <td>0.841177</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>6.034091</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.748955</td>\n",
       "      <td>0.061456</td>\n",
       "      <td>0.673112</td>\n",
       "      <td>0.835114</td>\n",
       "      <td>0.697522</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.474728</td>\n",
       "      <td>0.028856</td>\n",
       "      <td>0.428457</td>\n",
       "      <td>0.514222</td>\n",
       "      <td>0.513186</td>\n",
       "      <td>15.846154</td>\n",
       "      <td>4.355957</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.049865</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>0.425764</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>11.846154</td>\n",
       "      <td>6.681394</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  \\\n",
       "0  0.601387  0.020190  0.568930  0.631315  0.568930   2.222222  3.527668   \n",
       "1  0.862166  0.031436  0.794469  0.913501  0.841177   5.076923  6.034091   \n",
       "2  0.748955  0.061456  0.673112  0.835114  0.697522   6.000000  9.000000   \n",
       "3  0.474728  0.028856  0.428457  0.514222  0.513186  15.846154  4.355957   \n",
       "4  0.324100  0.049865  0.254478  0.425764  0.254478  11.846154  6.681394   \n",
       "\n",
       "   D_39_min  D_39_max  D_39_last  ...  D_63_nunique  D_64_count  D_64_last  \\\n",
       "0         0         8          4  ...             1           9          3   \n",
       "1         0        17          4  ...             1          13          0   \n",
       "2         0        23          0  ...             1          13          3   \n",
       "3         7        23         11  ...             1          13          2   \n",
       "4         1        26         26  ...             1          13          2   \n",
       "\n",
       "   D_64_nunique  D_66_count  D_66_last  D_66_nunique  D_68_count  D_68_last  \\\n",
       "0             2           9         -1             1           9          6   \n",
       "1             1          13         -1             1          13          6   \n",
       "2             2          13          1             1          13          4   \n",
       "3             1          13         -1             1          13          5   \n",
       "4             2          13         -1             1          13          5   \n",
       "\n",
       "   D_68_nunique  \n",
       "0             2  \n",
       "1             1  \n",
       "2             2  \n",
       "3             1  \n",
       "4             2  \n",
       "\n",
       "[5 rows x 918 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet(config[\"ENGINEERED_DATA\"] + \"test_fe.parquet\")\n",
    "test[test.columns[1:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6119d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(test[test.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d4556f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(config[\"SAMPLE_PATH\"])\n",
    "submit['prediction'] = preds\n",
    "submit.to_csv(config[\"SUBMISSION_FOLDER\"] + f'auto_gluon.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab127cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
